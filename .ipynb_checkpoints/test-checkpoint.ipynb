{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "be0c0a44-81e2-4811-8955-1c081cf60bc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import datetime\n",
    "from sklearn import preprocessing\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c12224e-f773-444b-9f6f-1503b4da7ce1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "228c7b6f-4d1a-4a1f-8e01-eace0fc1d289",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "865c13b7-182b-44c5-9198-9a7da3a9d753",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "ba98e161-3cce-42e0-8ba4-57fc5e6679c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Message (ML filter): after filtering we have 52395 records, starting at 2022-01-01 03:30:00 and ending at 2022-12-30 23:50:00.\n",
      "Training model with 7920 data points from 2022-05-25 00:00:00 until 2022-07-18 23:50:00.\n",
      "Predicting 1008 data points from 2022-07-19 00:00:00 until 2022-07-25 23:50:00.\n",
      "Accuracy: 71.03%\n",
      "Classification report: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           3       0.00      0.00      0.00        31\n",
      "          13       0.98      0.70      0.81       244\n",
      "          17       0.74      0.82      0.78       379\n",
      "          18       0.00      0.00      0.00         3\n",
      "          24       0.78      0.83      0.80       180\n",
      "          27       0.62      1.00      0.77        30\n",
      "          29       0.00      0.00      0.00         3\n",
      "          32       0.18      1.00      0.30        16\n",
      "          35       0.51      0.33      0.40       122\n",
      "\n",
      "    accuracy                           0.71      1008\n",
      "   macro avg       0.42      0.52      0.43      1008\n",
      "weighted avg       0.74      0.71      0.71      1008\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn import preprocessing\n",
    "import pandas as pd\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from Visualisations import HeatmapVisualizer\n",
    "import sys\n",
    "import warnings\n",
    "import sklearn.exceptions\n",
    "warnings.filterwarnings(\"ignore\", category=sklearn.exceptions.UndefinedMetricWarning)\n",
    "\n",
    "class Predict:\n",
    "    def __init__(self, df: pd.DataFrame, model_date_start: str, model_date_end: str, num_last_days_for_testing: int, heatmaps:bool = True) -> None:\n",
    "        self.df = df\n",
    "        self.model_date_start = model_date_start\n",
    "        self.model_date_end = model_date_end\n",
    "        self.num_last_days_for_testing = num_last_days_for_testing\n",
    "        self.heatmaps = heatmaps\n",
    "\n",
    "        self.main()\n",
    "\n",
    "    def main(self):\n",
    "        # Step 1. Load dataset.\n",
    "        self.load_data()\n",
    "\n",
    "        # Step 2. Make temporal features.\n",
    "        self.make_temporal_features()\n",
    "\n",
    "        # Step 3. Make train/test split.\n",
    "        self.make_train_test_split()\n",
    "\n",
    "        # Step 4. Run XGBoost model and make the predictions.\n",
    "        self.run_model()\n",
    "\n",
    "        # Step 5. Evaluate model performance.\n",
    "        self.evaluate_model()\n",
    "\n",
    "        # Step 6. Visualize the predictions, the actual values, and the training values in heatmaps.\n",
    "        if self.heatmaps:\n",
    "            self.visualize()\n",
    "\n",
    "    def load_data(self) -> pd.DataFrame:\n",
    "        # If df is None, it is not set, hence we have to load it from xlsx.\n",
    "        if self.df == None:\n",
    "            try:\n",
    "                self.df = pd.read_excel(\n",
    "                    \"output/resampled_df_10_min.xlsx\", index_col=[0]\n",
    "                )\n",
    "            except FileNotFoundError as e:\n",
    "                print(\n",
    "                    f\"{e}: Make sure to put your resampled_df_10_min.xlsx file in the 'output' folder.\"\n",
    "                )\n",
    "\n",
    "                sys.exit(1)\n",
    "\n",
    "        self.validate_data()\n",
    "        self.filter_data()\n",
    "        self.df_original = self.df.copy() # Make a copy of the original data so that we can compare the predictions with the original data (via heatmaps).\n",
    "\n",
    "        # We need to transform our string representations of locations to integers, for the ML models to work. \n",
    "        self.le = preprocessing.LabelEncoder()\n",
    "        self.df.location = self.le.fit_transform(self.df.location)\n",
    "\n",
    "        return self.df\n",
    "\n",
    "    def validate_data(self) -> None:\n",
    "        # Check if the loaded df satisfies all criteria.\n",
    "        if not \"time\" in self.df or not \"location\" in self.df:\n",
    "            raise ValueError(\n",
    "                \"Make sure that df contains both the columns 'time' (datetime) and 'location' (strings of locations)!\"\n",
    "            )\n",
    "\n",
    "    def filter_data(self) -> None:\n",
    "        self.df[self.df['time'].between(self.model_date_start, self.model_date_end)]\n",
    "\n",
    "        print(f\"Message (ML filter): after filtering we have {len(self.df)} records, starting at {str(self.df.iloc[0].time)} and ending at {str(self.df.iloc[-1].time)}.\")\n",
    "\n",
    "    def make_temporal_features(self) -> None:\n",
    "        self.df[\"weekday\"] = self.df[\"time\"].dt.dayofweek\n",
    "        self.df[\"hour\"] = self.df[\"time\"].dt.hour\n",
    "        self.df[\"day\"] = self.df[\"time\"].dt.day\n",
    "\n",
    "    def make_train_test_split(self) -> None:\n",
    "        # Define the end of training and the beginning of testing\n",
    "        self.train_end_date = self.model_date_end - pd.Timedelta(days=self.num_last_days_for_testing)\n",
    "        self.test_start_date = self.model_date_end - pd.Timedelta(days=self.num_last_days_for_testing) + pd.Timedelta(minutes=10)\n",
    "\n",
    "        # Create masks to filter the data based on dates\n",
    "        train_mask = self.df['time'].between(self.model_date_start, self.train_end_date)\n",
    "        test_mask = self.df['time'].between(self.test_start_date, self.model_date_end)\n",
    "\n",
    "        # Split the data into train and test sets\n",
    "        self.X_train = self.df.loc[train_mask, [\"weekday\", \"hour\", \"day\"]]\n",
    "        self.y_train = self.df.loc[train_mask, \"location\"]\n",
    "        self.X_test = self.df.loc[test_mask, [\"weekday\", \"hour\", \"day\"]]\n",
    "        self.y_test = self.df.loc[test_mask, \"location\"]\n",
    "\n",
    "    def run_model(self) -> None:\n",
    "        self.model = RandomForestClassifier()\n",
    "\n",
    "        print(f\"Training model with {len(self.X_train)} data points from {self.model_date_start} until {self.train_end_date}.\")\n",
    "\n",
    "        self.model.fit(self.X_train, self.y_train)\n",
    "        self.predictions = self.model.predict(self.X_test)\n",
    "\n",
    "        print(f\"Predicting {len(self.X_test)} data points from {self.test_start_date} until {self.model_date_end}.\")\n",
    "\n",
    "    def evaluate_model(self) -> None:\n",
    "        self.model_accuracy = accuracy_score(self.y_test, self.predictions)\n",
    "        print(\"Accuracy: %.2f%%\" % (self.model_accuracy * 100.0))\n",
    "\n",
    "        self.class_report = classification_report(self.y_test, self.predictions)\n",
    "        print(f\"Classification report: \\n{self.class_report}\")\n",
    "\n",
    "    def visualize(self) -> None:\n",
    "        # Create a datetime index with 10-minute intervals.\n",
    "        time_intervals = pd.date_range(\n",
    "            start=self.test_start_date, end=self.model_date_end, freq=\"10T\"\n",
    "        )\n",
    "\n",
    "        # Create a DataFrame with the 'time' column and the 'location' column that holds the predicted locations (strings).\n",
    "        df_predictions = pd.DataFrame(\n",
    "            {\n",
    "                \"time\": time_intervals,\n",
    "                \"location\": self.le.inverse_transform(self.predictions),\n",
    "            }\n",
    "        )\n",
    "\n",
    "        # Visualize the predictions in a heatmap and save it as heatmap_predicted.png.\n",
    "        HeatmapVisualizer(\n",
    "            str(self.test_start_date.date()),\n",
    "            str(self.model_date_end.date()),\n",
    "            df_predictions,\n",
    "            name=\"heatmap_predicted\",\n",
    "        )\n",
    "\n",
    "        # And also visualize the actual values in a heatmap named heatmap_actual.png\n",
    "        HeatmapVisualizer(\n",
    "            str(self.test_start_date.date()),\n",
    "            str(self.model_date_end.date()),\n",
    "            self.df_original, # Now we use the original dataframe (with time and location, 10 min intervals) to visualize the actual data.\n",
    "            name=\"heatmap_actual\",\n",
    "        )\n",
    "\n",
    "        # And lastly, visualize the training data as well as heatmap_training.png.\n",
    "        HeatmapVisualizer(\n",
    "            str(self.model_date_start.date()),\n",
    "            str(self.train_end_date.date()),\n",
    "            self.df_original, # Now we use the original dataframe (with time and location, 10 min intervals) to visualize the actual data.\n",
    "            name=\"heatmap_training\",\n",
    "        )\n",
    "\n",
    "\n",
    "p = Predict(\n",
    "    df=None, # Choose df = None if you want to load the dataframe from resampled_df_10_min.xlsx.\n",
    "    model_date_start=pd.to_datetime(\"2022-05-25 00:00:00\"),\n",
    "    model_date_end=pd.to_datetime(\"2022-07-25 23:50:00\"),\n",
    "    num_last_days_for_testing = 7,\n",
    "    heatmaps=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd6a3ea2-5156-433f-9ace-bf5a7d369299",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
