{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be0c0a44-81e2-4811-8955-1c081cf60bc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import datetime\n",
    "from sklearn import preprocessing\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from collections import Counter\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder as le\n",
    "from collections import defaultdict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c12224e-f773-444b-9f6f-1503b4da7ce1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_raw = pd.read_excel(\"output/resampled_df_10_min.xlsx\", index_col=[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2117e60a",
   "metadata": {},
   "outputs": [],
   "source": [
    "start_date = pd.to_datetime(f\"2023-01-01 00:00:00\")\n",
    "end_date = pd.to_datetime(f\"2023-05-01 23:50:00\")\n",
    "training_window_size = 7\n",
    "horizon_size = 7\n",
    "model_features = [\"day\", \"weekday\", \"hour\", \"window_block\"] # Day = day of the month (0-31), hour = hour of the day (0-24), weekday = day in the week (0-7), window_block = window block in the hour (0-5)\n",
    "\n",
    "baseline_performance = defaultdict(dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8e35ace",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df_raw[df_raw[\"time\"].between(start_date, end_date)].copy()\n",
    "\n",
    "label_encoder = le()\n",
    "df.location = label_encoder.fit_transform(df.location)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d82c26be",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"day\"] = df[\"time\"].dt.day\n",
    "df[\"weekday\"] = df[\"time\"].dt.dayofweek\n",
    "df[\"hour\"] = df[\"time\"].dt.hour\n",
    "df[\"window_block\"] = ((df['time'].dt.minute * 60 + df['time'].dt.second) // 600).astype(int)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12d02f6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02ab3575",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_start_date = start_date\n",
    "train_end_date = train_start_date + pd.Timedelta(days=training_window_size-1, hours=23, minutes=50)\n",
    "test_start_date = train_end_date + pd.Timedelta(minutes=10)\n",
    "test_end_date = test_start_date + pd.Timedelta(days=horizon_size-1, hours=23, minutes=50)\n",
    "\n",
    "train_mask = df[\"time\"].between(train_start_date, train_end_date)\n",
    "test_mask = df[\"time\"].between(test_start_date, test_end_date)\n",
    "\n",
    "# Split the data into train and test sets\n",
    "X_train = df.loc[train_mask, model_features]\n",
    "y_train = df.loc[train_mask, \"location\"]\n",
    "X_test = df.loc[test_mask, model_features]\n",
    "y_test = df.loc[test_mask, \"location\"]\n",
    "\n",
    "print(f\"Training: {train_start_date}-{train_end_date}, testing: {test_start_date}-{test_end_date}.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49621fff",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data = df.loc[train_mask]\n",
    "testing_data = df.loc[test_mask]\n",
    "most_common_locations = training_data.groupby(model_features)['location'].apply(lambda x: x.value_counts().idxmax()).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25e164db",
   "metadata": {},
   "outputs": [],
   "source": [
    "result_df = testing_data.merge(most_common_locations, how=\"left\", left_on=model_features, right_on=model_features)\n",
    "\n",
    "features_to_use = model_features[1:]\n",
    "while result_df['location_y'].isna().sum() > 0:\n",
    "    print('nan > 0, now trying with features: ', features_to_use)\n",
    "    most_common_locations = training_data[[\"location\"] + features_to_use].groupby(features_to_use)['location'].apply(lambda x: x.value_counts().idxmax()).reset_index()\n",
    "    result_df = testing_data.merge(most_common_locations, how=\"left\", left_on=features_to_use, right_on=features_to_use)\n",
    "    features_to_use = features_to_use[1:]  # Remove the first element to exclude it from the next merge\n",
    "\n",
    "predictions = result_df.location_y.values.tolist()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f24de744",
   "metadata": {},
   "outputs": [],
   "source": [
    "for d in range(horizon_size):\n",
    "    # Then, evaluate the baseline's predictions and store acc in self.baseline_performance\n",
    "    this_day_predictions = predictions[d*144:(d+1)*144]\n",
    "    this_day_actual_values = y_test[d*144:(d+1)*144]\n",
    "    acc = accuracy_score(this_day_actual_values, this_day_predictions)\n",
    "    print(f\"Acc of baseline: {acc}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1eda62d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "800f00a0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "718521f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Message (data loader): Since HOUR_OFFSET > 0, we offset the timestamps with 2 hours.\n",
      "Message (data loader): Loaded google_maps data from 2010-01-01 to 2023-12-30 with a fraction of 1. Length of data: 552928\n",
      "Message (data loader): First record in dataset is from 2014-09-04 15:17:59 and last record is from 2022-09-01 11:49:06\n",
      "Message (data loader): Performing EDA, saving plots at output/ankit1-100-30-1\n"
     ]
    }
   ],
   "source": [
    "import DataLoader as DL\n",
    "\n",
    "# Initialize parameters.\n",
    "data_source = \"google_maps\"  # Can be either 'google_maps' or 'routined'.\n",
    "# hours_offset is used to offset the timestamps to account for timezone differences. For google maps, timestamp comes in GMT+0\n",
    "# which means that we need to offset it by 2 hours to make it GMT+2 (Dutch timezone). Value must be INT!\n",
    "hours_offset = 2 # Should be 0 for routined and 2 for google_maps. \n",
    "# begin_date and end_date are used to filter the data for your analysis.\n",
    "begin_date = \"2010-01-01\"\n",
    "end_date = \"2023-12-30\"  # End date is INclusive! \n",
    "# FRACTION is used to make the DataFrame smaller. Final df = df * fraction. This solves memory issues, but a value of 1 is preferred.\n",
    "fraction = 1\n",
    "# For the heatmap visualization we specify a separate begin_date and end_date (must be between begin_date and end_date).\n",
    "# For readiness purposes, it it suggested to select between 2 and 14 days.\n",
    "heatmap_begin_date = \"2023-01-20\"\n",
    "heatmap_end_date = \"2023-05-28\"  # End date is INclusive! Choose a date that lies (preferably 2 days) before end_date to avoid errors. \n",
    "# For the model performance class we need to specify the number of training days (range) and testing horizon (also in days)\n",
    "training_window_size = 100\n",
    "horizon_size = 30\n",
    "window_step_size = 1\n",
    "outputs_folder_name = f\"ankit1-{training_window_size}-{horizon_size}-{window_step_size}\" # All of the outputs will be placed in output/outputs_folder_name\n",
    "\n",
    "df = DL.load_data(\n",
    "    data_source,\n",
    "    begin_date,\n",
    "    end_date,\n",
    "    fraction,\n",
    "    hours_offset,\n",
    "    outputs_folder_name=outputs_folder_name,\n",
    "    verbose=True,\n",
    "    perform_eda=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa2c749a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
